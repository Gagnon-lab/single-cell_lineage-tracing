{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best lineage barcode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to generate a barcode data frame with columns \"cell.id\", \"barcode.count\", \"barcode\", and \"site1-site10\" where cell.id corresponds to the 10X barcode, barcode. count is the number of unique lineage barcodes found in the cell, barcode is the full 10-site string of the edited barcode, and site1-site10 is the barcode separated into its 10 sites. The key here is that we only want to accept barcodes which belong to the majority percent of barcodes. This threshold is determined by what we see in the unedited data. We can pull ranked barcodes from the .allReadCounts file associated with the sample. An explanation of each step in this process is included in just the first example. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cleaner version of this script with user friendly functions will come later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inj_heat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"./data/10X_GESTALT_OUTPUT/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Take the first twelve barcodes. \n",
    "##### 12 was picked because .007 is the proportion of the top ranked edited barcode in the unedited control. The fourteenth barcode has a proportion below this noise threshold. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "['84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE', '3I+45+ATC_1D+73_5D+93&2I+101+AA_11I+125+TGTTTTTCTTT_1D+151_3I+180+TTC_10I+204+TTTTTAGATG&13D+210_6D+232_1D+259&1D+262_22D+268', '84D+42_84D+42_84D+42_84D+42_NONE_NONE_NONE_NONE_NONE_NONE', '1I+45+C_15D+66_NONE_9D+123_NONE_NONE_NONE_NONE_NONE_NONE', '3I+45+ATC_1D+73_30D+76_28D+114_3D+150&1I+155+A_20D+157_41D+206_41D+206_44D+257_44D+257', '1I+45+C_NONE_NONE_1D+126_NONE_NONE_NONE_NONE_NONE_NONE', '1I+45+C_26D+73_26D+73_NONE_NONE_NONE_NONE_NONE_NONE_NONE', '3I+45+ATC_1D+73_30D+76_28D+114_3D+150&1I+155+A_20D+157_23D+206_66D+234_66D+234_66D+234', '3I+45+ATC_1D+73_30D+76_28D+114_3D+150&1I+155+A_20D+157_23D+206_66D+233_66D+233_66D+233', '3I+45+ATC_1D+73_30D+76_28D+114_3D+150&1I+155+A_20D+157_41D+206_41D+206_46D+255_46D+255', '5D+42_16D+68_9D+91_NONE_13D+152_1D+179_3I+204+CAG_5I+231+GATTA&6I+236+TGATTA_1I+261+A_NONE', '46D+38_46D+38_7D+90_36D+105_2I+155+GA_1D+182_10I+204+CTAACGCACC&13D+208_5D+227&1I+235+A_3D+263_1D+287&5D+290']\n"
     ]
    }
   ],
   "source": [
    "barcodes_inj_heat1 = open(data_folder + \"inj_heat1/inj_heat1.allReadCounts\", \"r\")\n",
    "barcode_list_inj_heat1 = []\n",
    "barcodes_inj_heat1.readline()\n",
    "for line in barcodes_inj_heat1.readlines(): \n",
    "    line = line.split(\"\\t\")\n",
    "    barcode = line[0]\n",
    "    barcode = barcode.strip(\"\\t\")\n",
    "    barcode_list_inj_heat1.append(barcode)\n",
    "barcodes_inj_heat1.close()\n",
    "barcode_list_inj_heat1 = barcode_list_inj_heat1[:12]\n",
    "print(len(barcode_list_inj_heat1))\n",
    "print(barcode_list_inj_heat1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pull the 10X barcode, umi, and lineage barcode (site by site) from a .stats output file from a 10X-GESTALT run. Let's write that information to a new file and read it back in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('data/tables/inj_heat1_ID_umi_barcode.tsv', 'w')\n",
    "# write the header for the table\n",
    "output.write('cell.id' + '\\t' + 'umi' + '\\t' + 'PASS' + '\\t'+'site1' + '\\t' + \n",
    "              'site2'+ '\\t' + 'site3' + '\\t' + 'site4' + '\\t' + 'site5' + '\\t' +\n",
    "              'site6' + '\\t' + 'site7' '\\t' + 'site8' + '\\t' + 'site9' + '\\t' + 'site10' + '\\t'+'\\n')\n",
    "stats = open(data_folder + \"inj_heat1/inj_heat1.stats\", \"r\")\n",
    "stats.readline()\n",
    "# for each line in the stats file after the header\n",
    "for line in stats.readlines():\n",
    "    # split by underscore\n",
    "    read = line.split(\"_\")\n",
    "    # store the first 16 characters after the underscore as the cell_id\n",
    "    cell_id = read[1][:16]\n",
    "    # and the next 10 characters as the umi\n",
    "    umi = read[1][16:26]\n",
    "    # the barcode (nearly) is the 5th item when splitting by underscore\n",
    "    barcode = read[6]\n",
    "    # split the barcode by tab characters\n",
    "    barcode = barcode.split(\"\\t\")\n",
    "    # the second item of barcode is whether it was a pass or fail\n",
    "    PASS = barcode[1]\n",
    "    # and these indices match the sites of the barcode\n",
    "    site1 = barcode[22]\n",
    "    site2 = barcode[23]\n",
    "    site3 = barcode[24]\n",
    "    site4 = barcode[25]\n",
    "    site5 = barcode[26]\n",
    "    site6 = barcode[27]\n",
    "    site7 = barcode[28]\n",
    "    site8 = barcode[29]\n",
    "    site9 = barcode[30]\n",
    "    site10 = barcode[31]\n",
    "    # if the barcode passed in the stats file,\n",
    "    if PASS != 'FAIL':\n",
    "        # write it to the output table\n",
    "        output.write(str(cell_id) + '\\t' + str(umi) + '\\t' + str(PASS) + '\\t' + str(site1) + '\\t' + str(site2) + '\\t' +str(site3) + '\\t' +str(site4) + '\\t' +str(site5) + '\\t' +str(site6) + '\\t' +str(site7) + '\\t' +str(site8) + '\\t' +str(site9) + '\\t' +str(site10) + '\\n')                     \n",
    "output.close()\n",
    "stats.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary to hold barcode information for each cell\n",
    "stats_brief = open(\"data/tables/inj_heat1_ID_umi_barcode.tsv\", \"r\")\n",
    "stats_brief.readline()\n",
    "inj_heat1_dict = {}\n",
    "# for each line in the table we just wrote previously\n",
    "for line in stats_brief.readlines():\n",
    "    # split the line by tab character\n",
    "    line = line.split(\"\\t\")\n",
    "    # the first index is a cell (10X barcode)\n",
    "    cell = line[0]\n",
    "    # the third index is PASS\n",
    "    PASS = line[2]\n",
    "    # string together the barcode by site with underscores between each site\n",
    "    barcode = str(line[3]+'_'+line[4]+'_'+line[5]+'_'+line[6]+'_'+line[7]+'_'+line[8]+'_'+line[9]+'_'+line[10]+'_'+line[11]+'_'+line[12])\n",
    "    # remove the newline character at the end\n",
    "    barcode = barcode.strip(\"\\n\")\n",
    "    # pay attention only to those top twelve barcodes stored in barcode_list_inj_heat1\n",
    "    if barcode in barcode_list_inj_heat1:\n",
    "        # if the cell is already in the dictionary, add barcode to cell's list\n",
    "        if cell in inj_heat1_dict: \n",
    "            inj_heat1_dict[cell].append(barcode)\n",
    "        # otherwise, create list with the barcode for the cell\n",
    "        else: \n",
    "            inj_heat1_dict[cell] = [barcode]\n",
    "stats_brief.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are all the barcode reads associated with cell 'ATGTCCCCATTCACAG':\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "3I+45+ATC_1D+73_5D+93&2I+101+AA_11I+125+TGTTTTTCTTT_1D+151_3I+180+TTC_10I+204+TTTTTAGATG&13D+210_6D+232_1D+259&1D+262_22D+268\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n",
      "84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE\n"
     ]
    }
   ],
   "source": [
    "print(\"These are all the barcode reads associated with cell 'ATGTCCCCATTCACAG':\")\n",
    "for barcode in inj_heat1_dict['ATGTCCCCATTCACAG']: \n",
    "    print(barcode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count unique barcodes\n",
    "for cell in inj_heat1_dict.keys():\n",
    "    unique_barcodes = set(inj_heat1_dict[cell])\n",
    "    count = len(unique_barcodes)\n",
    "    # add count to the end of the cell list \n",
    "    inj_heat1_dict[cell].append(count)\n",
    "# find most abundant barcode\n",
    "for cell in inj_heat1_dict: \n",
    "    test = inj_heat1_dict[cell]\n",
    "    data = Counter(test)\n",
    "    abundant = max(test, key=data.get)\n",
    "    # repeat most abundant barcode at the end of the cell list\n",
    "    inj_heat1_dict[cell].append(abundant)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now if we look at the list associated with inj_heat1_dict['ATGTCCCCATTCACAG'], it will have two more values. The second to last is a number. This is the number of unique barcodes associated with that cell. The last value is the barcode that was most abundant in that cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, '84D+45_84D+45_84D+45_84D+45_NONE_NONE_NONE_NONE_NONE_NONE']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inj_heat1_dict['ATGTCCCCATTCACAG'][-2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now write output files for merging with Seurat object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = open('data/tables/inj_heat1_bestlineagebarcode.tsv', 'w')\n",
    "# write the header for this file\n",
    "output.write('cell.id' + '\\t' 'barcode.count' + '\\t' + 'top.barcode' + '\\t'+ 'site1'+ '\\t'+ \n",
    "             'site2'+ '\\t'+'site3'+ '\\t'+'site4'+ '\\t'+'site5'+ '\\t'+'site6'+ '\\t'+'site7'+ '\\t'+'site8'+ '\\t'+\n",
    "             'site9'+ '\\t'+'site10'+'\\n')\n",
    "# for each cell and barcode list in the dictionary\n",
    "for cell,barcode in inj_heat1_dict.items(): \n",
    "    # save the barcode as sites \n",
    "    sites = barcode[-1].split(\"_\")\n",
    "    # write the cell, number of unique barcodes in the cell, and the most abundant barcode in that cell \n",
    "    output.write(cell+'\\t'+str(barcode[-2])+'\\t'+barcode[0]+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                    +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instead of just the most abundant lineage barcode (top barcode or \"best\" barcode), write all barcodes for each cell to a file\n",
    "output = open('data/tables/inj_heat1_all_lineagebarcodes_filtered.tsv', 'w')\n",
    "output.write('cell.id' + '\\t' 'barcode.count' + '\\t' + 'barcodes' + '\\t'+ 'site1'+ '\\t'+ \n",
    "             'site2'+ '\\t'+'site3'+ '\\t'+'site4'+ '\\t'+'site5'+ '\\t'+'site6'+ '\\t'+'site7'+ '\\t'+'site8'+ '\\t'+\n",
    "             'site9'+ '\\t'+'site10'+'\\n')\n",
    "for cell,barcode in inj_heat1_dict.items(): \n",
    "    if len(inj_heat1_dict[cell]) == 3: \n",
    "        sites = barcode[-1].split(\"_\")\n",
    "        output.write(cell+'\\t'+str(barcode[-2])+'\\t'+barcode[0]+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                     +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "    elif len(inj_heat1_dict[cell]) >=3:\n",
    "        sites = barcode[0].split(\"_\")\n",
    "        output.write(cell+'\\t'+str(barcode[-2])+'\\t'+barcode[0]+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                     +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "        for i in range(1,len(inj_heat1_dict[cell])-2): \n",
    "            sites = barcode[i].split(\"_\")\n",
    "            output.write(' '+'\\t'+' '+'\\t'+str(barcode[i])+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                     +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inj_heat2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_inj_heat2 = open(data_folder + \"inj_heat2/inj_heat2.allReadCounts\", \"r\")\n",
    "barcode_list_inj_heat2 = []\n",
    "barcodes_inj_heat2.readline()\n",
    "for line in barcodes_inj_heat2.readlines(): \n",
    "    line = line.split(\"\\t\")\n",
    "    barcode = line[0]\n",
    "    barcode = barcode.strip(\"\\t\")\n",
    "    barcode_list_inj_heat2.append(barcode)\n",
    "barcodes_inj_heat2.close()\n",
    "barcode_list_inj_heat2 = barcode_list_inj_heat2[:13]\n",
    "\n",
    "output = open('data/tables/inj_heat2_ID_umi_barcode.tsv', 'w')\n",
    "output.write('cell.id' + '\\t' + 'umi' + '\\t' + 'PASS' + '\\t'+'site1' + '\\t' + \n",
    "              'site2'+ '\\t' + 'site3' + '\\t' + 'site4' + '\\t' + 'site5' + '\\t' +\n",
    "              'site6' + '\\t' + 'site7' '\\t' + 'site8' + '\\t' + 'site9' + '\\t' + 'site10' + '\\t'+'\\n')\n",
    "stats = open(data_folder + \"inj_heat2/inj_heat2.stats\", \"r\")\n",
    "stats.readline()\n",
    "for line in stats.readlines():\n",
    "    read = line.split(\"_\")\n",
    "    cell_id = read[1][:16]\n",
    "    umi = read[1][16:26]\n",
    "    barcode = read[6]\n",
    "    barcode = barcode.split(\"\\t\")\n",
    "    PASS = barcode[1]\n",
    "    site1 = barcode[22]\n",
    "    site2 = barcode[23]\n",
    "    site3 = barcode[24]\n",
    "    site4 = barcode[25]\n",
    "    site5 = barcode[26]\n",
    "    site6 = barcode[27]\n",
    "    site7 = barcode[28]\n",
    "    site8 = barcode[29]\n",
    "    site9 = barcode[30]\n",
    "    site10 = barcode[31]\n",
    "    if PASS != 'FAIL':\n",
    "        output.write(str(cell_id) + '\\t' + str(umi) + '\\t' + str(PASS) + '\\t' + str(site1) + '\\t' + str(site2) + '\\t' +str(site3) + '\\t' +str(site4) + '\\t' +str(site5) + '\\t' +str(site6) + '\\t' +str(site7) + '\\t' +str(site8) + '\\t' +str(site9) + '\\t' +str(site10) + '\\n')                     \n",
    "output.close()\n",
    "stats.close()\n",
    "\n",
    "stats_brief = open(\"data/tables/inj_heat2_ID_umi_barcode.tsv\", \"r\")\n",
    "stats_brief.readline()\n",
    "inj_heat2_dict = {}\n",
    "for line in stats_brief.readlines():\n",
    "    line = line.split(\"\\t\")\n",
    "    cell = line[0]\n",
    "    PASS = line[2]\n",
    "    barcode = str(line[3]+'_'+line[4]+'_'+line[5]+'_'+line[6]+'_'+line[7]+'_'+line[8]+'_'+line[9]+'_'+line[10]+'_'+line[11]+'_'+line[12])\n",
    "    barcode = barcode.strip(\"\\n\")\n",
    "    # pay attention to those top twelve barcodes stored in barcode_list_inj_heat2\n",
    "    if barcode in barcode_list_inj_heat2:\n",
    "        # if the cell is already in the dictionary, add barcode to cell's list\n",
    "        if cell in inj_heat2_dict: \n",
    "            inj_heat2_dict[cell].append(barcode)\n",
    "        # otherwise, create list with the barcode for the cell\n",
    "        else: \n",
    "            inj_heat2_dict[cell] = [barcode]\n",
    "stats_brief.close()\n",
    "\n",
    "# count unique barcodes\n",
    "for cell in inj_heat2_dict.keys():\n",
    "    unique_barcodes = set(inj_heat2_dict[cell])\n",
    "    count = len(unique_barcodes)\n",
    "    # add count to the end of the cell list \n",
    "    inj_heat2_dict[cell].append(count)\n",
    "# find most abundant barcode\n",
    "for cell in inj_heat2_dict: \n",
    "    test = inj_heat2_dict[cell]\n",
    "    data = Counter(test)\n",
    "    abundant = max(test, key=data.get)\n",
    "    # repeat most abundant barcode at the end of the cell list\n",
    "    inj_heat2_dict[cell].append(abundant)\n",
    "\n",
    "output = open('data/tables/inj_heat2_bestlineagebarcode.tsv', 'w')\n",
    "output.write('cell.id' + '\\t' 'barcode.count' + '\\t' + 'top.barcode' + '\\t'+ 'site1'+ '\\t'+ \n",
    "             'site2'+ '\\t'+'site3'+ '\\t'+'site4'+ '\\t'+'site5'+ '\\t'+'site6'+ '\\t'+'site7'+ '\\t'+'site8'+ '\\t'+\n",
    "             'site9'+ '\\t'+'site10'+'\\n')\n",
    "for cell,barcode in inj_heat2_dict.items(): \n",
    "    sites = barcode[-1].split(\"_\")\n",
    "    output.write(cell+'\\t'+str(barcode[-2])+'\\t'+barcode[0]+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                    +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "output.close()\n",
    "\n",
    "output = open('data/tables/inj_heat2_all_lineagebarcodes_filtered.tsv', 'w')\n",
    "output.write('cell.id' + '\\t' 'barcode.count' + '\\t' + 'barcodes' + '\\t'+ 'site1'+ '\\t'+ \n",
    "             'site2'+ '\\t'+'site3'+ '\\t'+'site4'+ '\\t'+'site5'+ '\\t'+'site6'+ '\\t'+'site7'+ '\\t'+'site8'+ '\\t'+\n",
    "             'site9'+ '\\t'+'site10'+'\\n')\n",
    "for cell,barcode in inj_heat2_dict.items(): \n",
    "    if len(inj_heat2_dict[cell]) == 3: \n",
    "        sites = barcode[-1].split(\"_\")\n",
    "        output.write(cell+'\\t'+str(barcode[-2])+'\\t'+barcode[0]+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                     +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "    elif len(inj_heat2_dict[cell]) >=3:\n",
    "        sites = barcode[0].split(\"_\")\n",
    "        output.write(cell+'\\t'+str(barcode[-2])+'\\t'+barcode[0]+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                     +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "        for i in range(1,len(inj_heat2_dict[cell])-2): \n",
    "            sites = barcode[i].split(\"_\")\n",
    "            output.write(' '+'\\t'+' '+'\\t'+str(barcode[i])+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                     +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  unedited1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_unedited1 = open(data_folder + \"unedited1/unedited1.allReadCounts\", \"r\")\n",
    "barcode_list_unedited1 = []\n",
    "barcodes_unedited1.readline()\n",
    "for line in barcodes_unedited1.readlines(): \n",
    "    line = line.split(\"\\t\")\n",
    "    barcode = line[0]\n",
    "    barcode = barcode.strip(\"\\t\")\n",
    "    barcode_list_unedited1.append(barcode)\n",
    "barcodes_unedited1.close()\n",
    "# NOTE: here we're just taking the top barcode since these are control samples \n",
    "# anything other than the unedited barcode is noise\n",
    "# if the top ranked barcode in your unedited control is not the unedited barcode, you should not trust this control\n",
    "barcode_list_unedited1 = barcode_list_unedited1[0]\n",
    "output = open('data/tables/unedited1_ID_umi_barcode.tsv', 'w')\n",
    "output.write('cell.id' + '\\t' + 'umi' + '\\t' + 'PASS' + '\\t'+'site1' + '\\t' + \n",
    "              'site2'+ '\\t' + 'site3' + '\\t' + 'site4' + '\\t' + 'site5' + '\\t' +\n",
    "              'site6' + '\\t' + 'site7' '\\t' + 'site8' + '\\t' + 'site9' + '\\t' + 'site10' + '\\t'+'\\n')\n",
    "stats = open(data_folder + \"unedited1/unedited1.stats\", \"r\")\n",
    "stats.readline()\n",
    "for line in stats.readlines():\n",
    "    read = line.split(\"_\")\n",
    "    cell_id = read[1][:16]\n",
    "    umi = read[1][16:26]\n",
    "    barcode = read[6]\n",
    "    barcode = barcode.split(\"\\t\")\n",
    "    PASS = barcode[1]\n",
    "    site1 = barcode[22]\n",
    "    site2 = barcode[23]\n",
    "    site3 = barcode[24]\n",
    "    site4 = barcode[25]\n",
    "    site5 = barcode[26]\n",
    "    site6 = barcode[27]\n",
    "    site7 = barcode[28]\n",
    "    site8 = barcode[29]\n",
    "    site9 = barcode[30]\n",
    "    site10 = barcode[31]\n",
    "    if PASS != 'FAIL':\n",
    "        output.write(str(cell_id) + '\\t' + str(umi) + '\\t' + str(PASS) + '\\t' + str(site1) + '\\t' + str(site2) + '\\t' +str(site3) + '\\t' +str(site4) + '\\t' +str(site5) + '\\t' +str(site6) + '\\t' +str(site7) + '\\t' +str(site8) + '\\t' +str(site9) + '\\t' +str(site10) + '\\n')                     \n",
    "output.close()\n",
    "stats.close()\n",
    "\n",
    "stats_brief = open(\"data/tables/unedited1_ID_umi_barcode.tsv\", \"r\")\n",
    "stats_brief.readline()\n",
    "unedited1_dict = {}\n",
    "for line in stats_brief.readlines():\n",
    "    line = line.split(\"\\t\")\n",
    "    cell = line[0]\n",
    "    PASS = line[2]\n",
    "    barcode = str(line[3]+'_'+line[4]+'_'+line[5]+'_'+line[6]+'_'+line[7]+'_'+line[8]+'_'+line[9]+'_'+line[10]+'_'+line[11]+'_'+line[12])\n",
    "    barcode = barcode.strip(\"\\n\")\n",
    "    # pay attention to those top twelve barcodes stored in barcode_list_unedited1\n",
    "    if barcode in barcode_list_unedited1:\n",
    "        # if the cell is already in the dictionary, add barcode to cell's list\n",
    "        if cell in unedited1_dict: \n",
    "            unedited1_dict[cell].append(barcode)\n",
    "        # otherwise, create list with the barcode for the cell\n",
    "        else: \n",
    "            unedited1_dict[cell] = [barcode]\n",
    "stats_brief.close()\n",
    "\n",
    "# count unique barcodes\n",
    "for cell in unedited1_dict.keys():\n",
    "    unique_barcodes = set(unedited1_dict[cell])\n",
    "    count = len(unique_barcodes)\n",
    "    # add count to the end of the cell list \n",
    "    unedited1_dict[cell].append(count)\n",
    "# find most abundant barcode\n",
    "for cell in unedited1_dict: \n",
    "    test = unedited1_dict[cell]\n",
    "    data = Counter(test)\n",
    "    abundant = max(test, key=data.get)\n",
    "    # repeat most abundant barcode at the end of the cell list\n",
    "    unedited1_dict[cell].append(abundant)\n",
    "\n",
    "output = open('data/tables/unedited1_bestlineagebarcode.tsv', 'w')\n",
    "output.write('cell.id' + '\\t' 'barcode.count' + '\\t' + 'top.barcode' + '\\t'+ 'site1'+ '\\t'+ \n",
    "             'site2'+ '\\t'+'site3'+ '\\t'+'site4'+ '\\t'+'site5'+ '\\t'+'site6'+ '\\t'+'site7'+ '\\t'+'site8'+ '\\t'+\n",
    "             'site9'+ '\\t'+'site10'+'\\n')\n",
    "for cell,barcode in unedited1_dict.items(): \n",
    "    sites = barcode[-1].split(\"_\")\n",
    "    output.write(cell+'\\t'+str(barcode[-2])+'\\t'+barcode[0]+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                    +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "output.close()\n",
    "\n",
    "output = open('data/tables/unedited1_all_lineagebarcodes_filtered.tsv', 'w')\n",
    "output.write('cell.id' + '\\t' 'barcode.count' + '\\t' + 'barcodes' + '\\t'+ 'site1'+ '\\t'+ \n",
    "             'site2'+ '\\t'+'site3'+ '\\t'+'site4'+ '\\t'+'site5'+ '\\t'+'site6'+ '\\t'+'site7'+ '\\t'+'site8'+ '\\t'+\n",
    "             'site9'+ '\\t'+'site10'+'\\n')\n",
    "for cell,barcode in unedited1_dict.items(): \n",
    "    if len(unedited1_dict[cell]) == 3: \n",
    "        sites = barcode[-1].split(\"_\")\n",
    "        output.write(cell+'\\t'+str(barcode[-2])+'\\t'+barcode[0]+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                     +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "    elif len(unedited1_dict[cell]) >=3:\n",
    "        sites = barcode[0].split(\"_\")\n",
    "        output.write(cell+'\\t'+str(barcode[-2])+'\\t'+barcode[0]+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                     +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "        for i in range(1,len(unedited1_dict[cell])-2): \n",
    "            sites = barcode[i].split(\"_\")\n",
    "            output.write(' '+'\\t'+' '+'\\t'+str(barcode[i])+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                     +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### unedited2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcodes_unedited2 = open(data_folder + \"unedited2/unedited2.allReadCounts\", \"r\")\n",
    "barcode_list_unedited2 = []\n",
    "barcodes_unedited2.readline()\n",
    "for line in barcodes_unedited2.readlines(): \n",
    "    line = line.split(\"\\t\")\n",
    "    barcode = line[0]\n",
    "    barcode = barcode.strip(\"\\t\")\n",
    "    barcode_list_unedited2.append(barcode)\n",
    "barcodes_unedited2.close()\n",
    "# notice here we're just taking the top barcode since these are control samples\n",
    "barcode_list_unedited2 = barcode_list_unedited2[0]\n",
    "output = open('data/tables/unedited2_ID_umi_barcode.tsv', 'w')\n",
    "output.write('cell.id' + '\\t' + 'umi' + '\\t' + 'PASS' + '\\t'+'site1' + '\\t' + \n",
    "              'site2'+ '\\t' + 'site3' + '\\t' + 'site4' + '\\t' + 'site5' + '\\t' +\n",
    "              'site6' + '\\t' + 'site7' '\\t' + 'site8' + '\\t' + 'site9' + '\\t' + 'site10' + '\\t'+'\\n')\n",
    "stats = open(data_folder + \"unedited2/unedited2.stats\", \"r\")\n",
    "stats.readline()\n",
    "for line in stats.readlines():\n",
    "    read = line.split(\"_\")\n",
    "    cell_id = read[1][:16]\n",
    "    umi = read[1][16:26]\n",
    "    barcode = read[6]\n",
    "    barcode = barcode.split(\"\\t\")\n",
    "    PASS = barcode[1]\n",
    "    site1 = barcode[22]\n",
    "    site2 = barcode[23]\n",
    "    site3 = barcode[24]\n",
    "    site4 = barcode[25]\n",
    "    site5 = barcode[26]\n",
    "    site6 = barcode[27]\n",
    "    site7 = barcode[28]\n",
    "    site8 = barcode[29]\n",
    "    site9 = barcode[30]\n",
    "    site10 = barcode[31]\n",
    "    if PASS != 'FAIL':\n",
    "        output.write(str(cell_id) + '\\t' + str(umi) + '\\t' + str(PASS) + '\\t' + str(site1) + '\\t' + str(site2) + '\\t' +str(site3) + '\\t' +str(site4) + '\\t' +str(site5) + '\\t' +str(site6) + '\\t' +str(site7) + '\\t' +str(site8) + '\\t' +str(site9) + '\\t' +str(site10) + '\\n')                     \n",
    "output.close()\n",
    "stats.close()\n",
    "\n",
    "stats_brief = open(\"data/tables/unedited2_ID_umi_barcode.tsv\", \"r\")\n",
    "stats_brief.readline()\n",
    "unedited2_dict = {}\n",
    "for line in stats_brief.readlines():\n",
    "    line = line.split(\"\\t\")\n",
    "    cell = line[0]\n",
    "    PASS = line[2]\n",
    "    barcode = str(line[3]+'_'+line[4]+'_'+line[5]+'_'+line[6]+'_'+line[7]+'_'+line[8]+'_'+line[9]+'_'+line[10]+'_'+line[11]+'_'+line[12])\n",
    "    barcode = barcode.strip(\"\\n\")\n",
    "    # pay attention to those top twelve barcodes stored in barcode_list_unedited2\n",
    "    if barcode in barcode_list_unedited2:\n",
    "        # if the cell is already in the dictionary, add barcode to cell's list\n",
    "        if cell in unedited2_dict: \n",
    "            unedited2_dict[cell].append(barcode)\n",
    "        # otherwise, create list with the barcode for the cell\n",
    "        else: \n",
    "            unedited2_dict[cell] = [barcode]\n",
    "stats_brief.close()\n",
    "\n",
    "# count unique barcodes\n",
    "for cell in unedited2_dict.keys():\n",
    "    unique_barcodes = set(unedited2_dict[cell])\n",
    "    count = len(unique_barcodes)\n",
    "    # add count to the end of the cell list \n",
    "    unedited2_dict[cell].append(count)\n",
    "# find most abundant barcode\n",
    "for cell in unedited2_dict: \n",
    "    test = unedited2_dict[cell]\n",
    "    data = Counter(test)\n",
    "    abundant = max(test, key=data.get)\n",
    "    # repeat most abundant barcode at the end of the cell list\n",
    "    unedited2_dict[cell].append(abundant)\n",
    "\n",
    "output = open('data/tables/unedited2_bestlineagebarcode.tsv', 'w')\n",
    "output.write('cell.id' + '\\t' 'barcode.count' + '\\t' + 'top.barcode' + '\\t'+ 'site1'+ '\\t'+ \n",
    "             'site2'+ '\\t'+'site3'+ '\\t'+'site4'+ '\\t'+'site5'+ '\\t'+'site6'+ '\\t'+'site7'+ '\\t'+'site8'+ '\\t'+\n",
    "             'site9'+ '\\t'+'site10'+'\\n')\n",
    "for cell,barcode in unedited2_dict.items(): \n",
    "    sites = barcode[-1].split(\"_\")\n",
    "    output.write(cell+'\\t'+str(barcode[-2])+'\\t'+barcode[0]+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                    +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "output.close()\n",
    "\n",
    "output = open('data/tables/unedited2_all_lineagebarcodes_filtered.tsv', 'w')\n",
    "output.write('cell.id' + '\\t' 'barcode.count' + '\\t' + 'barcodes' + '\\t'+ 'site1'+ '\\t'+ \n",
    "             'site2'+ '\\t'+'site3'+ '\\t'+'site4'+ '\\t'+'site5'+ '\\t'+'site6'+ '\\t'+'site7'+ '\\t'+'site8'+ '\\t'+\n",
    "             'site9'+ '\\t'+'site10'+'\\n')\n",
    "for cell,barcode in unedited2_dict.items(): \n",
    "    if len(unedited2_dict[cell]) == 3: \n",
    "        sites = barcode[-1].split(\"_\")\n",
    "        output.write(cell+'\\t'+str(barcode[-2])+'\\t'+barcode[0]+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                     +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "    elif len(unedited2_dict[cell]) >=3:\n",
    "        sites = barcode[0].split(\"_\")\n",
    "        output.write(cell+'\\t'+str(barcode[-2])+'\\t'+barcode[0]+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                     +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "        for i in range(1,len(unedited2_dict[cell])-2): \n",
    "            sites = barcode[i].split(\"_\")\n",
    "            output.write(' '+'\\t'+' '+'\\t'+str(barcode[i])+'\\t'+sites[0]+'\\t'+sites[1]+'\\t'+sites[2]\n",
    "                     +'\\t'+sites[3]+'\\t'+sites[4]+'\\t'+sites[5]+'\\t'+sites[6]+'\\t'+sites[7]+'\\t'+sites[8]\n",
    "                     +'\\t'+sites[9]+'\\n')\n",
    "output.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
